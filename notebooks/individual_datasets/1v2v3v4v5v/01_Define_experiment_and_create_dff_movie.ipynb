{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a17f07e-e09c-4fba-9b41-87ffe1d7bfaa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-06-23T03:00:38.543362200Z",
     "start_time": "2023-06-23T03:00:34.877714700Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# data manager and analysis\n",
    "import vodex as vx\n",
    "import numan as nu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a91d2431",
   "metadata": {},
   "source": [
    "### Packages and versions when this notebook was last tested:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46aa95a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T04:43:43.628980600Z",
     "start_time": "2023-06-23T04:43:39.932910600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package             Version\n",
      "------------------- -----------\n",
      "asttokens           2.0.8\n",
      "attrs               22.1.0\n",
      "backcall            0.2.0\n",
      "beautifulsoup4      4.11.1\n",
      "bleach              5.0.1\n",
      "certifi             2022.6.15\n",
      "colorama            0.4.5\n",
      "cycler              0.11.0\n",
      "debugpy             1.6.3\n",
      "decorator           5.1.1\n",
      "defusedxml          0.7.1\n",
      "entrypoints         0.4\n",
      "executing           0.10.0\n",
      "fastjsonschema      2.16.1\n",
      "fonttools           4.37.0\n",
      "ipykernel           6.15.1\n",
      "ipython             8.4.0\n",
      "jedi                0.18.1\n",
      "Jinja2              3.1.2\n",
      "jsonschema          4.14.0\n",
      "jupyter-client      7.3.4\n",
      "jupyter-core        4.11.1\n",
      "jupyterlab-pygments 0.2.2\n",
      "kiwisolver          1.4.4\n",
      "lxml                4.9.1\n",
      "MarkupSafe          2.1.1\n",
      "matplotlib          3.5.3\n",
      "matplotlib-inline   0.1.6\n",
      "mistune             2.0.4\n",
      "nbclient            0.6.7\n",
      "nbconvert           7.0.0\n",
      "nbformat            5.4.0\n",
      "nest-asyncio        1.5.5\n",
      "numan               1.0.5\n",
      "numpy               1.23.2\n",
      "packaging           21.3\n",
      "pandas              1.4.3\n",
      "pandocfilters       1.5.0\n",
      "parso               0.8.3\n",
      "pathlib             1.0.1\n",
      "pickleshare         0.7.5\n",
      "Pillow              9.2.0\n",
      "pip                 22.1.2\n",
      "prompt-toolkit      3.0.30\n",
      "psutil              5.9.1\n",
      "pure-eval           0.2.2\n",
      "Pygments            2.13.0\n",
      "pyparsing           3.0.9\n",
      "PyPDF2              2.10.3\n",
      "pyrsistent          0.18.1\n",
      "python-dateutil     2.8.2\n",
      "pytz                2022.2.1\n",
      "pywin32             304\n",
      "pyzmq               23.2.1\n",
      "reportlab           3.6.11\n",
      "scipy               1.9.0\n",
      "setuptools          63.4.1\n",
      "six                 1.16.0\n",
      "soupsieve           2.3.2.post1\n",
      "stack-data          0.4.0\n",
      "tifffile            2022.8.12\n",
      "tinycss2            1.1.1\n",
      "tornado             6.2\n",
      "tqdm                4.64.0\n",
      "traitlets           5.3.0\n",
      "urllib3             1.26.12\n",
      "vodex               1.0.2\n",
      "wcwidth             0.2.5\n",
      "webencodings        0.5.1\n",
      "wheel               0.37.1\n",
      "wincertstore        0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ced75f57-3ae0-4e1c-ab34-f5e5010fdc97",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Project structure: \n",
    "\n",
    "Provide the project folder, then the \"processed\" folder will be created inside. \n",
    "\n",
    "As you keep going with the analysis, the folder will have the following structure: \n",
    "\n",
    "```\n",
    "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "+++++++++++++ WILL BE DONE in this notebook +++++++++++++++\n",
    "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "processed                                               +++\n",
    "│   experiment_raw.json <-------------------------------+++ the file that contains the volume information about the experiment, you are creating it once and will be reusing ever after\n",
    "│   experiment_dff.json <-------------------------------+++ the experiment, but files are loaded from the dff movie folder, not from the raw data               \n",
    "└───dff_movie  <----------------------------------------+++ the dff movie folder, will be created by this notebook\n",
    "│   │   dff_movie_0000.tif                              +++ individual tif files with the dff movie\n",
    "│   │   dff_movie_0001.tif                              +++\n",
    "│   │   ...                                             +++\n",
    "│++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "│++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "│++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "│\n",
    "└───tscore_volumes  <-------------------------------------- WILL BE DONE in 02\n",
    "│   │   tscore_SvB.tif <-----------------------------------\n",
    "└───spots\n",
    "│   └───imaris  <------------------------------------------ Manual Step: export the spots from Imaris\n",
    "│       │   └───tscore_SvB_Statistics\n",
    "│       │       │     tscore_SvB_Position.csv\n",
    "│       │       │     tscore_SvB_Diameter.csv\n",
    "│       │       │     ...\n",
    "│   └───signals  <----------------------------------------- WILL BE DONE in 03\n",
    "│       │   spots_SvB.json\n",
    "│   └───reports  <-----------------------------------------   \n",
    "│       └───all_significant  <-----------------------------    \n",
    "│           │   └───signals  <-----------------------------   \n",
    "│           │       │     ...\n",
    "│           │   └───images <-------------------------------    \n",
    "│           │       │     ...\n",
    "│       └───groupped  <------------------------------------    \n",
    "│           │   readme.txt  <------------------------------ Manual Step: export the spots from Imaris\n",
    "│           │   └───signals  <-----------------------------    \n",
    "│           │       │     ...\n",
    "│           │   └───images  <------------------------------    \n",
    "│           │       │     ...\n",
    "```\n",
    "# Set project folder\n",
    "Also, if the processed folder exists, it will complain ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bba63983-c186-45a2-8e24-913465354f12",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-06-23T03:00:40.085886600Z",
     "start_time": "2023-06-23T03:00:40.079886Z"
    }
   },
   "outputs": [],
   "source": [
    "# please provedi FULL, not relative, path to the folder \n",
    "project_folder = \"D:/Data/Numerosity/hz09\"\n",
    "project = nu.Project(project_folder)\n",
    "project.create(\"processed\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf7bad9f-c4ad-4628-b979-0a0a828fa630",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We will also set the processed directory as our working directory, this step is important , since all the paths later are relative to this folder. Verify that the output of the cell is the \"processed\" folder inside your project folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5d736f2-2ade-41f1-87b2-132cc0dab2eb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-06-23T03:00:42.600462700Z",
     "start_time": "2023-06-23T03:00:42.545737300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'D:\\\\Data\\\\Numerosity\\\\hz09\\\\processed'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.activate(\"processed\")\n",
    "os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4273882-09e6-48a1-ae05-18a63f5b5f70",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Define experiment: \n",
    "\n",
    "* First you need to provide the path to the folder with the **raw data**, ```data_dir```. Note that by default the code will search for all the .tif files in that folder and will treat it as raw data. While you can exclude the unwanted files later, it is recommended that three is only raw tif data in that folder. Make sure to use either ```\\\\``` or ```/``` as a separator, not ```\\```, as it is an escape character in python.\n",
    "\n",
    "* provide the number of **frames per volume**\n",
    "\n",
    "* Then you need to define the **labels**.\n",
    "\n",
    "* Then, if your experiment has a **repeating cycle**, you will need to order labels as they appear in a cycle in and provide the corresponding duration for each label. Note that the duration is in frames, as they appear in your image data, not in seconds, not in volumes.\n",
    "\n",
    "This will initialise experiment and output the experiment information. Read it carefully! Make sure it is all as expected! Any mistake at this step will make all the future analysis wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d0692e7-a75c-48eb-be7d-c12439e77abb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-06-23T03:01:09.031500500Z",
     "start_time": "2023-06-23T03:00:47.429744500Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<tifffile.TiffTag 270 @269649> coercing invalid ASCII to bytes\n",
      "<tifffile.TiffTag 270 @269649> coercing invalid ASCII to bytes\n",
      "<tifffile.TiffTag 270 @269649> coercing invalid ASCII to bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image files information :\n",
      "\n",
      "files directory: D:\\Data\\Numerosity\\hz09\\20230601_Hz09_casper_h2bcamp7f_7dpf_60Z_1hzvol_2P_1v2v3v4v5_1\n",
      "files [number of frames]: \n",
      "0) 20230601_Hz09_casper_h2bcamp7f_7dpf_60Z_1hzvol_2P_1v2v3v4v5_1_MMStack_Pos0.ome.tif [12877]\n",
      "1) 20230601_Hz09_casper_h2bcamp7f_7dpf_60Z_1hzvol_2P_1v2v3v4v5_1_MMStack_Pos0_1.ome.tif [12876]\n",
      "2) 20230601_Hz09_casper_h2bcamp7f_7dpf_60Z_1hzvol_2P_1v2v3v4v5_1_MMStack_Pos0_2.ome.tif [12876]\n",
      "3) 20230601_Hz09_casper_h2bcamp7f_7dpf_60Z_1hzvol_2P_1v2v3v4v5_1_MMStack_Pos0_3.ome.tif [12876]\n",
      "4) 20230601_Hz09_casper_h2bcamp7f_7dpf_60Z_1hzvol_2P_1v2v3v4v5_1_MMStack_Pos0_4.ome.tif [12876]\n",
      "5) 20230601_Hz09_casper_h2bcamp7f_7dpf_60Z_1hzvol_2P_1v2v3v4v5_1_MMStack_Pos0_5.ome.tif [12876]\n",
      "6) 20230601_Hz09_casper_h2bcamp7f_7dpf_60Z_1hzvol_2P_1v2v3v4v5_1_MMStack_Pos0_6.ome.tif [12876]\n",
      "7) 20230601_Hz09_casper_h2bcamp7f_7dpf_60Z_1hzvol_2P_1v2v3v4v5_1_MMStack_Pos0_7.ome.tif [12876]\n",
      "8) 20230601_Hz09_casper_h2bcamp7f_7dpf_60Z_1hzvol_2P_1v2v3v4v5_1_MMStack_Pos0_8.ome.tif [12876]\n",
      "9) 20230601_Hz09_casper_h2bcamp7f_7dpf_60Z_1hzvol_2P_1v2v3v4v5_1_MMStack_Pos0_9.ome.tif [12876]\n",
      "\n",
      "Total frames : 128761\n",
      "Volumes start on frame : 0\n",
      "Total good volumes : 2146\n",
      "Frames per volume : 60\n",
      "Tailing frames (not a full volume , at the end) : 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# files info\n",
    "data_dir = \"D:/Data/Numerosity/hz09/20230601_Hz09_casper_h2bcamp7f_7dpf_60Z_1hzvol_2P_1v2v3v4v5_1\"\n",
    "\n",
    "# volumes info\n",
    "frames_per_volume = 60\n",
    "# starting_slice is zero if the recording starts exactly at the beginning of a full volume, \n",
    "# must be set to a slice where the recording starts (zero-based), slices > 0 if the recording starts somewhere in the middle of the volume:\n",
    "starting_slice = 0 \n",
    "\n",
    "# initialise experiment\n",
    "experiment = vx.Experiment.from_dir(data_dir, frames_per_volume,starting_slice, verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e0f0008-6ef1-4280-9ba4-00e123068bc5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Make sure everything above is correct** and then , if it is , save it for future use.\n",
    "This will create a database, for more information see https://lemonjust.github.io/vodex/db/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b91e508d-a35b-4d10-b42e-097ac478fd49",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-06-23T03:01:09.121010100Z",
     "start_time": "2023-06-23T03:01:09.032501800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied 2552 of 2552 pages...\n"
     ]
    }
   ],
   "source": [
    "experiment.save(\"experiment_raw.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Denoising"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "project.create(\"processed/removed_offset\")\n",
    "offset_file = \"D:/Data/Numerosity/denoising_2023/16_32_64_128_256_512_1024/calibration_offset.tif\"\n",
    "\n",
    "# batch size 25 takes about 30 Gb of RAM to process\n",
    "batch_size = 50 # in volumes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T03:01:12.154261600Z",
     "start_time": "2023-06-23T03:01:12.134231100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lemon\\miniconda3\\envs\\numan\\lib\\site-packages\\vodex\\experiment.py:109: UserWarning: The are some frames at the end of the recording that don't correspond to a full volume.\n",
      "  warnings.warn(f\"The are some frames at the end of the recording \"\n",
      "D:\\Code\\repos\\numan\\src\\numan\\analysis.py:706: UserWarning: Some image values belov zero after subtracting the offset image. Will be set to zero.\n",
      "  warnings.warn(f\"Some image values belov zero after subtracting the offset image. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written volumes : 50, out of 2146 full volumes\n",
      "written volumes : 100, out of 2146 full volumes\n",
      "written volumes : 150, out of 2146 full volumes\n",
      "written volumes : 200, out of 2146 full volumes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<tifffile.TiffTag 270 @269649> coercing invalid ASCII to bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written volumes : 250, out of 2146 full volumes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<tifffile.TiffTag 270 @269649> coercing invalid ASCII to bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written volumes : 300, out of 2146 full volumes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<tifffile.TiffTag 270 @269649> coercing invalid ASCII to bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written volumes : 350, out of 2146 full volumes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<tifffile.TiffTag 270 @269649> coercing invalid ASCII to bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written volumes : 400, out of 2146 full volumes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<tifffile.TiffTag 270 @269649> coercing invalid ASCII to bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written volumes : 450, out of 2146 full volumes\n",
      "written volumes : 500, out of 2146 full volumes\n",
      "written volumes : 550, out of 2146 full volumes\n",
      "written volumes : 600, out of 2146 full volumes\n",
      "written volumes : 650, out of 2146 full volumes\n",
      "written volumes : 700, out of 2146 full volumes\n",
      "written volumes : 750, out of 2146 full volumes\n",
      "written volumes : 800, out of 2146 full volumes\n",
      "written volumes : 850, out of 2146 full volumes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<tifffile.TiffTag 270 @269649> coercing invalid ASCII to bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written volumes : 900, out of 2146 full volumes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<tifffile.TiffTag 270 @269649> coercing invalid ASCII to bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written volumes : 950, out of 2146 full volumes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<tifffile.TiffTag 270 @269649> coercing invalid ASCII to bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written volumes : 1000, out of 2146 full volumes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<tifffile.TiffTag 270 @269649> coercing invalid ASCII to bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written volumes : 1050, out of 2146 full volumes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<tifffile.TiffTag 270 @269649> coercing invalid ASCII to bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written volumes : 1100, out of 2146 full volumes\n",
      "written volumes : 1150, out of 2146 full volumes\n",
      "written volumes : 1200, out of 2146 full volumes\n",
      "written volumes : 1250, out of 2146 full volumes\n",
      "written volumes : 1300, out of 2146 full volumes\n",
      "written volumes : 1350, out of 2146 full volumes\n",
      "written volumes : 1400, out of 2146 full volumes\n",
      "written volumes : 1450, out of 2146 full volumes\n",
      "written volumes : 1500, out of 2146 full volumes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<tifffile.TiffTag 270 @269649> coercing invalid ASCII to bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written volumes : 1550, out of 2146 full volumes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<tifffile.TiffTag 270 @269649> coercing invalid ASCII to bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written volumes : 1600, out of 2146 full volumes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<tifffile.TiffTag 270 @269649> coercing invalid ASCII to bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written volumes : 1650, out of 2146 full volumes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<tifffile.TiffTag 270 @269649> coercing invalid ASCII to bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written volumes : 1700, out of 2146 full volumes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<tifffile.TiffTag 270 @269649> coercing invalid ASCII to bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written volumes : 1750, out of 2146 full volumes\n",
      "written volumes : 1800, out of 2146 full volumes\n",
      "written volumes : 1850, out of 2146 full volumes\n",
      "written volumes : 1900, out of 2146 full volumes\n",
      "written volumes : 1950, out of 2146 full volumes\n",
      "written volumes : 2000, out of 2146 full volumes\n",
      "written volumes : 2050, out of 2146 full volumes\n",
      "written volumes : 2100, out of 2146 full volumes\n",
      "written volumes : 2146, out of 2146 full volumes\n"
     ]
    }
   ],
   "source": [
    "nu.Preprocess(experiment).remove_offset('removed_offset',batch_size, offset_file = offset_file,\n",
    "                                        verbose=True )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T03:10:42.857663200Z",
     "start_time": "2023-06-23T03:01:15.163373800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image files information :\n",
      "\n",
      "files directory: removed_offset\n",
      "files [number of frames]: \n",
      "0) removed_offset_movie_0000.tif [3000]\n",
      "1) removed_offset_movie_0001.tif [3000]\n",
      "2) removed_offset_movie_0002.tif [3000]\n",
      "3) removed_offset_movie_0003.tif [3000]\n",
      "4) removed_offset_movie_0004.tif [3000]\n",
      "5) removed_offset_movie_0005.tif [3000]\n",
      "6) removed_offset_movie_0006.tif [3000]\n",
      "7) removed_offset_movie_0007.tif [3000]\n",
      "8) removed_offset_movie_0008.tif [3000]\n",
      "9) removed_offset_movie_0009.tif [3000]\n",
      "10) removed_offset_movie_0010.tif [3000]\n",
      "11) removed_offset_movie_0011.tif [3000]\n",
      "12) removed_offset_movie_0012.tif [3000]\n",
      "13) removed_offset_movie_0013.tif [3000]\n",
      "14) removed_offset_movie_0014.tif [3000]\n",
      "15) removed_offset_movie_0015.tif [3000]\n",
      "16) removed_offset_movie_0016.tif [3000]\n",
      "17) removed_offset_movie_0017.tif [3000]\n",
      "18) removed_offset_movie_0018.tif [3000]\n",
      "19) removed_offset_movie_0019.tif [3000]\n",
      "20) removed_offset_movie_0020.tif [3000]\n",
      "21) removed_offset_movie_0021.tif [3000]\n",
      "22) removed_offset_movie_0022.tif [3000]\n",
      "23) removed_offset_movie_0023.tif [3000]\n",
      "24) removed_offset_movie_0024.tif [3000]\n",
      "25) removed_offset_movie_0025.tif [3000]\n",
      "26) removed_offset_movie_0026.tif [3000]\n",
      "27) removed_offset_movie_0027.tif [3000]\n",
      "28) removed_offset_movie_0028.tif [3000]\n",
      "29) removed_offset_movie_0029.tif [3000]\n",
      "30) removed_offset_movie_0030.tif [3000]\n",
      "31) removed_offset_movie_0031.tif [3000]\n",
      "32) removed_offset_movie_0032.tif [3000]\n",
      "33) removed_offset_movie_0033.tif [3000]\n",
      "34) removed_offset_movie_0034.tif [3000]\n",
      "35) removed_offset_movie_0035.tif [3000]\n",
      "36) removed_offset_movie_0036.tif [3000]\n",
      "37) removed_offset_movie_0037.tif [3000]\n",
      "38) removed_offset_movie_0038.tif [3000]\n",
      "39) removed_offset_movie_0039.tif [3000]\n",
      "40) removed_offset_movie_0040.tif [3000]\n",
      "41) removed_offset_movie_0041.tif [3000]\n",
      "42) removed_offset_movie_0042.tif [2760]\n",
      "\n",
      "Total frames : 128760\n",
      "Volumes start on frame : 0\n",
      "Total good volumes : 2146\n",
      "Frames per volume : 60\n",
      "Tailing frames (not a full volume , at the end) : 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment.close()\n",
    "# update files info to use the new dff_movie folder instead of the original data_dir\n",
    "data_dir = \"removed_offset\"\n",
    "\n",
    "# create new experiment\n",
    "experiment = vx.Experiment.from_dir(data_dir, frames_per_volume, starting_slice, verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T03:17:25.734601300Z",
     "start_time": "2023-06-23T03:17:23.658146900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Drift correction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b15c2081-cfc0-442c-9178-1b4e127e7d53",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Create dff movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5caf43b4-22e7-4738-8830-f98d876c76b3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "project.create(\"processed/dff_movie\")\n",
    "\n",
    "# batch size 25 takes about 30 Gb of RAM to process\n",
    "batch_size = 100 # in volumes\n",
    "window_size = 15 # in volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32b8bd42-49d7-49a7-827e-d860f50e1f0c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ply/miniconda3/envs/numan/lib/python3.11/site-packages/vodex/experiment.py:601: UserWarning: list_volumes will be removed in vodex 1.1.0 use volumes property instead.\n",
      "  warnings.warn(f\"list_volumes will be removed in vodex 1.1.0 use volumes property instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written frames : 0 - 92, out of 1984\n",
      "written frames : 93 - 178, out of 1984\n",
      "written frames : 179 - 264, out of 1984\n",
      "written frames : 265 - 350, out of 1984\n",
      "written frames : 351 - 436, out of 1984\n",
      "written frames : 437 - 522, out of 1984\n",
      "written frames : 523 - 608, out of 1984\n",
      "written frames : 609 - 694, out of 1984\n",
      "written frames : 695 - 780, out of 1984\n",
      "written frames : 781 - 866, out of 1984\n",
      "written frames : 867 - 952, out of 1984\n",
      "written frames : 953 - 1038, out of 1984\n",
      "written frames : 1039 - 1124, out of 1984\n",
      "written frames : 1125 - 1210, out of 1984\n",
      "written frames : 1211 - 1296, out of 1984\n",
      "written frames : 1297 - 1382, out of 1984\n",
      "written frames : 1383 - 1468, out of 1984\n",
      "written frames : 1469 - 1554, out of 1984\n",
      "written frames : 1555 - 1640, out of 1984\n",
      "written frames : 1641 - 1726, out of 1984\n",
      "written frames : 1727 - 1812, out of 1984\n",
      "written frames : 1813 - 1898, out of 1984\n",
      "written frames : 1899 - 1983, out of 1984\n"
     ]
    }
   ],
   "source": [
    "nu.Preprocess(experiment).batch_dff('dff_movie',batch_size, window_size, blur_sigma = 1, verbose=True )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "608fb189-627e-4239-b97a-10d3592f330c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Now cerate an experiment that uses dff_movie as the data\n",
    "Before we make a new experiment, let's close the databse connection of the existing one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4712c1d-37cf-4e97-9e6e-40f6b68c0a4f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image files information :\n",
      "\n",
      "files directory: dff_movie\n",
      "files [number of frames]: \n",
      "0) dff_movie_0000.tif [6231]\n",
      "1) dff_movie_0001.tif [5762]\n",
      "2) dff_movie_0002.tif [5762]\n",
      "3) dff_movie_0003.tif [5762]\n",
      "4) dff_movie_0004.tif [5762]\n",
      "5) dff_movie_0005.tif [5762]\n",
      "6) dff_movie_0006.tif [5762]\n",
      "7) dff_movie_0007.tif [5762]\n",
      "8) dff_movie_0008.tif [5762]\n",
      "9) dff_movie_0009.tif [5762]\n",
      "10) dff_movie_0010.tif [5762]\n",
      "11) dff_movie_0011.tif [5762]\n",
      "12) dff_movie_0012.tif [5762]\n",
      "13) dff_movie_0013.tif [5762]\n",
      "14) dff_movie_0014.tif [5762]\n",
      "15) dff_movie_0015.tif [5762]\n",
      "16) dff_movie_0016.tif [5762]\n",
      "17) dff_movie_0017.tif [5762]\n",
      "18) dff_movie_0018.tif [5762]\n",
      "19) dff_movie_0019.tif [5762]\n",
      "20) dff_movie_0020.tif [5762]\n",
      "21) dff_movie_0021.tif [5762]\n",
      "22) dff_movie_0022.tif [5695]\n",
      "\n",
      "Total frames : 132928\n",
      "Volumes start on frame : 0\n",
      "Total good volumes : 1984\n",
      "Frames per volume : 67\n",
      "Tailing frames (not a full volume , at the end) : 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment.close()\n",
    "# update files info to use the new dff_movie folder instead of the original data_dir\n",
    "data_dir = \"dff_movie\"\n",
    "\n",
    "# create new experiment\n",
    "experiment = vx.Experiment.from_dir(data_dir, frames_per_volume, starting_slice, verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84bee0b0-02fc-4a44-b791-718198a92513",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Make sure everything except the filenames looks identical to the experiment we defined at the beginning** and then , if it does , save it for future use: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied 2643 of 2643 pages...\n"
     ]
    }
   ],
   "source": [
    "experiment.save(\"experiment_dff.db\")\n",
    "experiment.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "numan",
   "language": "python",
   "display_name": "numan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "6249b6f06ab4a0845821264d60e7cf9277af2fa14153329fa82794ff3205396b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
