{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "153f028e-542f-4056-bdc9-64dbde5763b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# plotting \n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "# progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# data manager and analysis\n",
    "import vodex as vx\n",
    "import numan as nu\n",
    "\n",
    "# writing files\n",
    "import tifffile as tif\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9676731e-3e8d-4286-9ab3-e55a0af491a7",
   "metadata": {},
   "source": [
    "# Project structure: \n",
    "\n",
    "Provide the project folder with the \"processed\" folder created in the previous notebook. \n",
    "\n",
    "As you keep going with the analysis, the folder will have the following structure: \n",
    "\n",
    "```\n",
    "processed\n",
    "│   experiment.json <----------------------------------- (DONE in 01) the file that contains everything about the experiment, you are creating it once at the beginning of the processing and reusing ever after\n",
    "└───dff_movie  <---------------------------------------- (DONE in 01) the dff movie :) \n",
    "│   │   dff_movie_0000.tif\n",
    "│   │   dff_movie_0001.tif\n",
    "│   │   ... \n",
    "└───tscore_volumes  <----------------------------------- (DONE in 02) t-score tif files per pair\n",
    "│   └───2v3\n",
    "│       │   tscore_2v3.tif\n",
    "│   └───3v5\n",
    "│       │   tscore_3v5.tif\n",
    "│   └───2v5\n",
    "│       │   tscore_2v5.tif\n",
    "│   └───2vB\n",
    "│       │   tscore_2vB.tif\n",
    "│   └───3vB\n",
    "│       │   tscore_3vB.tif\n",
    "│   └───5vB\n",
    "│       │   tscore_5vB.tif\n",
    "│   └───BvB1\n",
    "│       │   tscore_BvB1.tif\n",
    "│   └───BvB2\n",
    "│       │   tscore_BvB2.tif\n",
    "│   └───BvB3\n",
    "│       │   tscore_BvB3.tif\n",
    "└───diff_volumes  <------------------------------------- (DONE in 02) absolute difference tif files per pair\n",
    "│   └───2v3\n",
    "│       │   diff_2v3.tif\n",
    "│   └───3v5\n",
    "│       │   diff_3v5.tif\n",
    "│   └───...\n",
    "└───spots\n",
    "│   └───imaris  <--------------------------------------- (DONE after 02) ATTENTION : You need to put stuff generated by imaris into this folder!!! \n",
    "│       │   └───tscore_2v3_Statistics\n",
    "│       │       │     tscore_2v3_Position.csv\n",
    "│       │       │     tscore_2v3_Diameter.csv\n",
    "│       │       │     ...\n",
    "│       │   └───tscore_3v5_Statistics\n",
    "│       │       │     tscore_3v5_Position.csv\n",
    "│       │       │     tscore_3v5_Diameter.csv\n",
    "│       │       │     ...\n",
    "│       │   └───tscore_2v5_Statistics\n",
    "│       │       │     ...\n",
    "│       │   └───...\n",
    "│   └───signals  <-------------------------------------- (DONE in 03 and 04, WILL BE UPDATED in this notebook) json files with the extracted signals, also will have the group info after you added it\n",
    "│       │   spots_2v3.json\n",
    "│       │   spots_3v5.json\n",
    "│       │   spots_2v5.json\n",
    "│       │     ...\n",
    "│       └───reports  <---------------------------------- tiffs and pdf with the cells significant in any pairwise comparison\n",
    "│       │   └───all_significant  <---------------------- tiffs and pdf with all significant cells per group\n",
    "│       │       │   └───signals  <---------------------- (WILL BE DONE in this notebook) pdfs with signals\n",
    "│       │       │       │     ...\n",
    "│       │       │   └───images <------------------------ tif masks \n",
    "│       │       │       │     ...\n",
    "│       │   └───groupped  <----------------------------- tiffs and pdf where the cells are groupped based on signal shape .. or anything else you want\n",
    "│       │       │   readme.txt  <----------------------- ATTENTION : you need to describe the groups\n",
    "│       │       │   └───signals  <---------------------- pdfs with signals\n",
    "│       │       │       │     ...\n",
    "│       │       │   └───images  <----------------------- tif masks \n",
    "│       │       │       │     ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b1f086-d071-43d5-898b-9360f40c2bf2",
   "metadata": {},
   "source": [
    "# Set project folder\n",
    "\n",
    "The processed/spots/signals should already exist and have the extracted signals saved in there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0656dbc1-f3c0-4004-aa58-9d56c1f80da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Code\\\\repos\\\\numan\\\\notebooks\\\\data\\\\2vs3vs5\\\\processed'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_folder = \"D:/Code/repos/numan/notebooks/data/2vs3vs5/\"\n",
    "path = os.path.join(project_folder, 'processed')\n",
    "\n",
    "assert os.path.isdir( os.path.join(path, \"spots\", \"signals\")), \"the directory 'processed/spots/signals' doesn't exist in the project,\" \\\n",
    "                                \" did you forget to run the previous notebook?\"\n",
    "\n",
    "os.chdir(path)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220cf5f8-4c64-4a7f-9a1d-be9b96e2e8d8",
   "metadata": {},
   "source": [
    "# Load experiment with the raw data and define conditions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecc8295-096d-4e14-8637-460a1ed0ed36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiment = vx.from_json(vx.Experiment,'experiment.json')\n",
    "experiment.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010c06b1-0650-4d78-9888-7422ee2bc24f",
   "metadata": {},
   "source": [
    "## Create lots of pdfs with lots of traces : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b62871-c255-4139-99ac-117f40e4336b",
   "metadata": {},
   "source": [
    "Since we have so much different ways that a cell can be significant, I think I'll just out put all the cells that are significant in any way at all .. and will indicate the way that they are significant ... Not the best way of doing things in general.. but oh well... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11800ad6-a609-46b4-82e7-8138fcb47e07",
   "metadata": {},
   "source": [
    "## Find the cells that are significant in any way "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f30f5afa-ebbd-4deb-a23b-c1efe2e670d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_sig_summary(groups_per_spot, ever_significant):\n",
    "    # sort by length and in alphabetical order\n",
    "    groups_per_spot = np.array(groups_per_spot)[ever_significant].tolist()\n",
    "    groups_per_spot.sort(key=len, reverse=True)\n",
    "    groups_per_spot = np.array(groups_per_spot)\n",
    "\n",
    "    n_sig = np.sum(ever_significant)\n",
    "    n_tot = len(ever_significant)\n",
    "\n",
    "    print(f\"{n_sig}/{n_tot} spots are ever significant. \\nBelow are their types.\\n\")\n",
    "    for group_name in groups_per_spot:\n",
    "        print(group_name)\n",
    "        \n",
    "def get_ever_significnt(spots, verbose = False):\n",
    "    # different categories in which we test if a spot is significant \n",
    "    sig_categories = [\"sig2v3\", \"sig2v5\", \"sig3v5\", \"sig2vB\", \"sig3vB\", \"sig5vB\"] \n",
    "    groups_per_spot = spots.get_group_info(sig_categories).tolist()\n",
    "    # significant in at least one category\n",
    "    ever_significant = [len(group)>0 for group in groups_per_spot] \n",
    "    \n",
    "    if verbose: \n",
    "        all_sig_summary(groups_per_spot, ever_significant)\n",
    "        \n",
    "    return ever_significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c74382-95d8-41f5-9337-9c04a6539944",
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_tag = \"2v3\"\n",
    "print(f\"\\n{spot_tag}__________________________________________________\")\n",
    "spots = nu.Spots.from_json(f\"spots/signals/spots_{spot_tag}.json\")\n",
    "ever_significant = get_ever_significnt(spots, verbose = True)\n",
    "spots.add_groups({\"sigAny2v3v5vB\":ever_significant})\n",
    "spots.to_json(f\"spots/signals/spots_{spot_tag}.json\")\n",
    "\n",
    "spot_tag = \"2v5\"\n",
    "print(f\"\\n{spot_tag}__________________________________________________\")\n",
    "spots = nu.Spots.from_json(f\"spots/signals/spots_{spot_tag}.json\")\n",
    "ever_significant = get_ever_significnt(spots, verbose = True)\n",
    "spots.add_groups({\"sigAny2v3v5vB\":ever_significant})\n",
    "spots.to_json(f\"spots/signals/spots_{spot_tag}.json\")\n",
    "\n",
    "spot_tag = \"3v5\"\n",
    "print(f\"\\n{spot_tag}__________________________________________________\")\n",
    "spots = nu.Spots.from_json(f\"spots/signals/spots_{spot_tag}.json\")\n",
    "ever_significant = get_ever_significnt(spots, verbose = True)\n",
    "spots.add_groups({\"sigAny2v3v5vB\":ever_significant})\n",
    "spots.to_json(f\"spots/signals/spots_{spot_tag}.json\")\n",
    "\n",
    "spot_tag = \"2vB\"\n",
    "print(f\"\\n{spot_tag}__________________________________________________\")\n",
    "spots = nu.Spots.from_json(f\"spots/signals/spots_{spot_tag}.json\")\n",
    "ever_significant = get_ever_significnt(spots, verbose = True)\n",
    "spots.add_groups({\"sigAny2v3v5vB\":ever_significant})\n",
    "spots.to_json(f\"spots/signals/spots_{spot_tag}.json\")\n",
    "\n",
    "spot_tag = \"3vB\"\n",
    "print(f\"\\n{spot_tag}__________________________________________________\")\n",
    "spots = nu.Spots.from_json(f\"spots/signals/spots_{spot_tag}.json\")\n",
    "ever_significant = get_ever_significnt(spots, verbose = True)\n",
    "spots.add_groups({\"sigAny2v3v5vB\":ever_significant})\n",
    "spots.to_json(f\"spots/signals/spots_{spot_tag}.json\")\n",
    "\n",
    "spot_tag = \"5vB\"\n",
    "print(f\"\\n{spot_tag}__________________________________________________\")\n",
    "spots = nu.Spots.from_json(f\"spots/signals/spots_{spot_tag}.json\")\n",
    "ever_significant = get_ever_significnt(spots, verbose = True)\n",
    "spots.add_groups({\"sigAny2v3v5vB\":ever_significant})\n",
    "spots.to_json(f\"spots/signals/spots_{spot_tag}.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd80a0c-5deb-4a17-ba5a-bdde94621fdb",
   "metadata": {},
   "source": [
    "Add the \" ever significant\" group to the spots groups to treat is as one of the spot types, and save the spots. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f45309-4da8-4323-babf-f3fcb9c8355a",
   "metadata": {},
   "source": [
    "## Create a folder and initialise the reports maker  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "2a533226-0773-4cdd-bd55-2efe049b46b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All reports will be in : D:/Code/repos/numan/notebooks/data/2vs3vs5/processed\\spots\\reports\\all_significant\\signals\n"
     ]
    }
   ],
   "source": [
    "reports_folder = os.path.join(path, 'spots','reports', 'all_significant','signals')\n",
    "os.makedirs(reports_folder)\n",
    "rep = nu.Reports(path, experiment)\n",
    "\n",
    "print(f\"All reports will be in : {reports_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c27774-6552-4a6e-99e9-0db5c8b9dfd9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Make cycle plots: \n",
    "Without individual traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "886b5e06-79a2-4f27-a285-0d31a59b2606",
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_tags = [\"2v3\",\"2v5\",\"3v5\",\"2vB\",\"3vB\",\"5vB\"]\n",
    "for spot_tag in tqdm(spot_tags):\n",
    "    rep.make_signal_reports(spot_tag, \"sigAny2v3v5vB\", \n",
    "            # types of plots: \n",
    "            plot_type = \"cycle\", \n",
    "            # just for the pdf naming : \n",
    "            # this is to be able to distinguish the pdfs with the same plot type, \n",
    "            # but errors are different or raw traces on/off or front_to_tail\n",
    "            plot_type_tag = '',\n",
    "            # wether or not you want to have the cells sorted on how many tests they passes\n",
    "            sort_by_sig = True, \n",
    "            # front_to_tail will shift the cycleby the set number of voxels\n",
    "            # so when set to 3, there are 3 blank volumes at the begining and at the end ...\n",
    "            # if set to 0, will have 6 leading blanks and will end right after the 5 dots (black bar)\n",
    "            front_to_tail=0,\n",
    "            # what error type to use ( \"sem\" for SEM or \"prc\" for 5th - 95th percentile )\n",
    "            error_type=\"sem\",\n",
    "            # wheather to plot the individual traces\n",
    "            plot_individual=False,\n",
    "            # the color of the individual traces (if shown)\n",
    "            noise_color='-c')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa717519-daaa-4d18-9d9a-1df604eb80c2",
   "metadata": {},
   "source": [
    "With individual traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "91fe7355-9b6e-4192-ac0b-c53ab146feab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spot_tags = [\"2v3\",\"2v5\",\"3v5\",\"2vB\",\"3vB\",\"5vB\"]\n",
    "for spot_tag in tqdm(spot_tags):\n",
    "    rep.make_signal_reports(spot_tag, \"sigAny2v3v5vB\", \n",
    "                # types of plots: \n",
    "                plot_type = \"cycle\", \n",
    "                # just for the pdf naming : \n",
    "                # this is to be able to distinguish the pdfs with the same plot type, \n",
    "                # but errors are different or raw traces on/off or front_to_tail\n",
    "                plot_type_tag = '_individ_traces',\n",
    "                # wether or not you want to have the cells sorted on how many tests they passes\n",
    "                sort_by_sig = True, \n",
    "                # front_to_tail will shift the cycleby the set number of voxels\n",
    "                # so when set to 3, there are 3 blank volumes at the begining and at the end ...\n",
    "                # if set to 0, will have 6 leading blanks and will end right after the 5 dots (black bar)\n",
    "                front_to_tail=3,\n",
    "                # what error type to use ( \"sem\" for SEM or \"prc\" for 5th - 95th percentile )\n",
    "                error_type=\"sem\",\n",
    "                # wheather to plot the individual traces\n",
    "                plot_individual=True,\n",
    "                # the color of the individual traces (if shown)\n",
    "                noise_color='-c')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b06778e-ee65-492c-b2b5-df8ca6b2f26c",
   "metadata": {},
   "source": [
    "## Make PSH plots: \n",
    "### Only stimulus \n",
    "List the cycle timepoints that you want to show and ovrelap ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3b2ea4-7275-4df8-876c-17985ff24c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATTENTION ! This is specific to the current experiment !!! \n",
    "# here it means that it will overlap timepoints 13, 27 and 43 from the cycle ( this is when we're showing 2 dots ) ... and will show it first on the plot , \n",
    "# then it will overlap time points 7, 37, 60 (dot 3 ) and show that .. etc \n",
    "time_points = [[13, 7, 20],[27, 37, 53],[43, 60, 70]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "85367d46-fe1c-4b62-b8e6-5a9705883ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_tags = [\"2v3\",\"2v5\",\"3v5\",\"2vB\",\"3vB\",\"5vB\"]\n",
    "for spot_tag in tqdm(spot_tags):\n",
    "    rep.make_signal_reports(spot_tag, \"sigAny2v3v5vB\", \n",
    "                # types of plots: \n",
    "                plot_type = \"psh_0\", \n",
    "                # just for the pdf naming : \n",
    "                # this is to be able to distinguish the pdfs with the same plot type, \n",
    "                # but errors are different or raw traces on/off or front_to_tail\n",
    "                plot_type_tag = '',\n",
    "                # only show certain timepoints from the signal, for example : only 2 dots\n",
    "                time_points=time_points,\n",
    "                # wether or not you want to have the cells sorted on how many tests they passes\n",
    "                sort_by_sig = True, \n",
    "                # what error type to use ( \"sem\" for SEM or \"prc\" for 5th - 95th percentile )\n",
    "                error_type=\"sem\",\n",
    "                # wheather to plot the individual traces\n",
    "                plot_individual=False,\n",
    "                # the color of the individual traces (if shown)\n",
    "                noise_color='-c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2a913d-2440-4cf0-a170-d4ca78149193",
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_tags = [\"2v3\",\"2v5\",\"3v5\",\"2vB\",\"3vB\",\"5vB\"]\n",
    "for spot_tag in  tqdm(spot_tags):\n",
    "    rep.make_signal_reports(spot_tag, \"sigAny2v3v5vB\", \n",
    "                # types of plots: \n",
    "                plot_type = \"psh_0\", \n",
    "                # just for the pdf naming : \n",
    "                # this is to be able to distinguish the pdfs with the same plot type, \n",
    "                # but errors are different or raw traces on/off or front_to_tail\n",
    "                plot_type_tag = '_individ_traces',\n",
    "                # only show certain timepoints from the signal, for example : only 2 dots\n",
    "                time_points=time_points,\n",
    "                # wether or not you want to have the cells sorted on how many tests they passes\n",
    "                sort_by_sig = True, \n",
    "                # what error type to use ( \"sem\" for SEM or \"prc\" for 5th - 95th percentile )\n",
    "                error_type=\"sem\",\n",
    "                # wheather to plot the individual traces\n",
    "                plot_individual=True,\n",
    "                # the color of the individual traces (if shown)\n",
    "                noise_color='-c')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5208c7b-06c3-4564-89c2-01bd3137294c",
   "metadata": {},
   "source": [
    "### Stimulus + some blanks before and after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a36f5cfd-6b47-49a1-8dd9-1d468fc68826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_timpoints(bb, ba, time_centers):\n",
    "    \"\"\"\n",
    "    Adds the bb and ba number of blanks around each value in time_centers, \n",
    "    keeping the number of rows the same.\n",
    "    \"\"\"\n",
    "    time_points = np.zeros((3,((bb + ba)+1)*3))\n",
    "    for it, t in enumerate(time_centers):\n",
    "        a,b,c = t\n",
    "        a_long = np.concatenate((a - np.arange(bb + 1)[::-1] , a + 1 + np.arange(ba) ))\n",
    "        b_long = np.concatenate((b - np.arange(bb + 1)[::-1] , b + 1 + np.arange(ba) ))\n",
    "        c_long = np.concatenate((c - np.arange(bb + 1)[::-1] , c + 1 + np.arange(ba) ))\n",
    "        time_points[it] = np.concatenate((a_long,b_long,c_long))\n",
    "    time_points = time_points.astype(int)\n",
    "    return time_points\n",
    "\n",
    "\n",
    "# Choose the number of blanks before and after the stimulus\n",
    "N_BLANKS_BEFORE_STIM = 3\n",
    "N_BLANKS_AFTER_STIM = 5\n",
    "\n",
    "# Create the timepoints to overlap in the right order\n",
    "time_centers = [[13, 7, 20],[27, 37, 53],[43, 60, 70]]\n",
    "time_points = generate_timpoints(N_BLANKS_BEFORE_STIM, N_BLANKS_AFTER_STIM, time_centers)\n",
    "time_points[2,-N_BLANKS_AFTER_STIM:] = np.arange(N_BLANKS_AFTER_STIM)\n",
    "# create a way to break the lines on the plot (to visually separate different stimuli)\n",
    "signal_split = np.array([np.arange(N_BLANKS_BEFORE_STIM + N_BLANKS_AFTER_STIM + 1),\n",
    "             np.arange(N_BLANKS_BEFORE_STIM + N_BLANKS_AFTER_STIM + 1)+(N_BLANKS_BEFORE_STIM + N_BLANKS_AFTER_STIM + 1), \n",
    "             np.arange(N_BLANKS_BEFORE_STIM + N_BLANKS_AFTER_STIM + 1)+(N_BLANKS_BEFORE_STIM + N_BLANKS_AFTER_STIM + 1)*2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "ca07810b-238b-4a65-9834-f9744f029cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_tags = [\"2v3\",\"2v5\",\"3v5\",\"2vB\",\"3vB\",\"5vB\"]\n",
    "for spot_tag in tqdm(spot_tags):\n",
    "    rep.make_signal_reports(spot_tag, \"sigAny2v3v5vB\", \n",
    "                # types of plots: \n",
    "                plot_type = \"psh_b\", \n",
    "                # just for the pdf naming : \n",
    "                # this is to be able to distinguish the pdfs with the same plot type, \n",
    "                # but errors are different or raw traces on/off or front_to_tail\n",
    "                plot_type_tag = '',\n",
    "                # only show certain timepoints from the signal, for example : only 2 dots\n",
    "                time_points = time_points,\n",
    "                # how to break the line \n",
    "                signal_split = signal_split,\n",
    "                # draw vertical lines\n",
    "                vlines = [8.5, 17.5],\n",
    "                # wether or not you want to have the cells sorted on how many tests they passes\n",
    "                sort_by_sig = True, \n",
    "                # what error type to use ( \"sem\" for SEM or \"prc\" for 5th - 95th percentile )\n",
    "                error_type=\"sem\",\n",
    "                # wheather to plot the individual traces\n",
    "                plot_individual=False,\n",
    "                # the color of the individual traces (if shown)\n",
    "                noise_color='-c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a57e2f69-f562-430f-8c4a-b3a712ef5799",
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_tags = [\"2v3\",\"2v5\",\"3v5\",\"2vB\",\"3vB\",\"5vB\"]\n",
    "for spot_tag in tqdm(spot_tags):\n",
    "    rep.make_signal_reports(spot_tag, \"sigAny2v3v5vB\", \n",
    "                # types of plots: \n",
    "                plot_type = \"psh_b\", \n",
    "                # just for the pdf naming : \n",
    "                # this is to be able to distinguish the pdfs with the same plot type, \n",
    "                # but errors are different or raw traces on/off or front_to_tail\n",
    "                plot_type_tag = '_individ_traces',\n",
    "                # only show certain timepoints from the signal, for example : only 2 dots\n",
    "                time_points = time_points,\n",
    "                # how to break the line \n",
    "                signal_split = signal_split,\n",
    "                # draw vertical lines\n",
    "                vlines = [8.5, 17.5],\n",
    "                # wether or not you want to have the cells sorted on how many tests they passes\n",
    "                sort_by_sig = True, \n",
    "                # what error type to use ( \"sem\" for SEM or \"prc\" for 5th - 95th percentile )\n",
    "                error_type=\"sem\",\n",
    "                # wheather to plot the individual traces\n",
    "                plot_individual=True,\n",
    "                # the color of the individual traces (if shown)\n",
    "                noise_color='-c')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
